{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "In this notebook, we showcase how to fine-tune the Qwen3-1.7B model on AWS Trainium using the Hugging Face Optimum Neuron library.\n",
    "The goal of this task is Text-to-SQL generation â€” training the model to translate natural language questions into executable SQL queries.\n",
    "\n",
    "We will fine-tune the model using `optimum.neuron`, save the trained checkpoint, and then deploy it for inference with Optimum-Neuron[vllm], enabling high-performance, low-latency Text-to-SQL execution.\n",
    "\n",
    "By the end of this notebook, youâ€™ll have a fine-tuned, Trainium-optimized Qwen3 model ready for deployment and real-time inference. This workflow demonstrates how to leverage the Optimum Neuron toolchain to efficiently train and serve large language models on AWS Neuron devices.\n",
    "\n",
    "For this module, you will be using the [b-mc2/sql-create-context](https://huggingface.co/datasets/b-mc2/sql-create-context) dataset which consists of thousands of examples of SQL schemas, questions about the schemas, and SQL queries intended to answer the questions.\n",
    "\n",
    "*Dataset example 1:*\n",
    "* *SQL schema/context:* `CREATE TABLE management (department_id VARCHAR); CREATE TABLE department (department_id VARCHAR)`\n",
    "* *Question:* `How many departments are led by heads who are not mentioned?`\n",
    "* *SQL query/answer:* `SELECT COUNT(*) FROM department WHERE NOT department_id IN (SELECT department_id FROM management)`\n",
    "\n",
    "*Dataset example 2:*\n",
    "* *SQL schema/context:* `CREATE TABLE courses (course_name VARCHAR, course_id VARCHAR); CREATE TABLE student_course_registrations (student_id VARCHAR, course_id VARCHAR)`\n",
    "* *Question:* `What are the ids of all students for courses and what are the names of those courses?`\n",
    "* *SQL query/answer:* `SELECT T1.student_id, T2.course_name FROM student_course_registrations AS T1 JOIN courses AS T2 ON T1.course_id = T2.course_id`\n",
    "\n",
    "By fine-tuning the model over several thousand of these text-to-SQL examples, the model will then learn how to generate an appropriate SQL query when presented with a SQL context and a free-form question.\n",
    "\n",
    "This text-to-SQL use case was selected so you can successfully fine-tune your model in a reasonably short amount of time (~25 minutes) which is appropriate for this workshop. Although this is a relatively simple use case, please keep in mind that the same techniques and components used in this module can also be applied to fine-tune LLMs for more advanced use cases such as writing code, summarizing documents, creating blog posts - the possibilities are endless!\n",
    "\n",
    "# Install requirements\n",
    "This notebook uses [Hugging Face Optimum Neuron](https://github.com/huggingface/optimum-neuron) which works like an interface between the Hugging Face Transformers library and AWS Accelerators including AWS Trainium and AWS Inferentia. We will also install some other libraries like peft, trl etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/environment/FineTuning/HuggingFaceExample/01_finetuning/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: optimum-neuron==0.3.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (0.3.0)\n",
      "Requirement already satisfied: peft==0.16.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (0.16.0)\n",
      "Requirement already satisfied: trl==0.11.4 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (0.11.4)\n",
      "Requirement already satisfied: huggingface_hub==0.33.4 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (0.33.4)\n",
      "Requirement already satisfied: datasets==3.6.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (3.6.0)\n",
      "Requirement already satisfied: transformers~=4.51.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from optimum-neuron==0.3.0->-r requirements.txt (line 1)) (4.51.3)\n",
      "Requirement already satisfied: accelerate==1.8.1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from optimum-neuron==0.3.0->-r requirements.txt (line 1)) (1.8.1)\n",
      "Requirement already satisfied: optimum~=1.24.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from optimum-neuron==0.3.0->-r requirements.txt (line 1)) (1.24.0)\n",
      "Requirement already satisfied: numpy<=1.25.2,>=1.22.2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from optimum-neuron==0.3.0->-r requirements.txt (line 1)) (1.25.2)\n",
      "Requirement already satisfied: protobuf<4,>=3.20.3 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from optimum-neuron==0.3.0->-r requirements.txt (line 1)) (3.20.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from peft==0.16.0->-r requirements.txt (line 2)) (24.2)\n",
      "Requirement already satisfied: psutil in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from peft==0.16.0->-r requirements.txt (line 2)) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from peft==0.16.0->-r requirements.txt (line 2)) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from peft==0.16.0->-r requirements.txt (line 2)) (2.7.0)\n",
      "Requirement already satisfied: tqdm in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from peft==0.16.0->-r requirements.txt (line 2)) (4.67.1)\n",
      "Requirement already satisfied: safetensors in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from peft==0.16.0->-r requirements.txt (line 2)) (0.5.3)\n",
      "Requirement already satisfied: tyro>=0.5.11 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from trl==0.11.4->-r requirements.txt (line 3)) (0.9.35)\n",
      "Requirement already satisfied: filelock in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from huggingface_hub==0.33.4->-r requirements.txt (line 4)) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from huggingface_hub==0.33.4->-r requirements.txt (line 4)) (2025.3.0)\n",
      "Requirement already satisfied: requests in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from huggingface_hub==0.33.4->-r requirements.txt (line 4)) (2.32.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from huggingface_hub==0.33.4->-r requirements.txt (line 4)) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from huggingface_hub==0.33.4->-r requirements.txt (line 4)) (1.2.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from datasets==3.6.0->-r requirements.txt (line 5)) (22.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from datasets==3.6.0->-r requirements.txt (line 5)) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from datasets==3.6.0->-r requirements.txt (line 5)) (2.3.1)\n",
      "Requirement already satisfied: xxhash in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from datasets==3.6.0->-r requirements.txt (line 5)) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from datasets==3.6.0->-r requirements.txt (line 5)) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 5)) (3.12.15)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from transformers~=4.51.0->optimum-neuron==0.3.0->-r requirements.txt (line 1)) (2025.7.34)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from transformers~=4.51.0->optimum-neuron==0.3.0->-r requirements.txt (line 1)) (0.21.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 5)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 5)) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 5)) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 5)) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 5)) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 5)) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 5)) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 5)) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets==3.6.0->-r requirements.txt (line 5)) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from requests->huggingface_hub==0.33.4->-r requirements.txt (line 4)) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from requests->huggingface_hub==0.33.4->-r requirements.txt (line 4)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from requests->huggingface_hub==0.33.4->-r requirements.txt (line 4)) (2025.7.14)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (2.8.8)\n",
      "Requirement already satisfied: jinja2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (3.3.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from triton==3.3.0->torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (1.3.0)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.11.4->-r requirements.txt (line 3)) (0.17.0)\n",
      "Requirement already satisfied: rich>=11.1.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.11.4->-r requirements.txt (line 3)) (14.1.0)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.11.4->-r requirements.txt (line 3)) (1.7.2)\n",
      "Requirement already satisfied: typeguard>=4.0.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.11.4->-r requirements.txt (line 3)) (4.4.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.11.4->-r requirements.txt (line 3)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.11.4->-r requirements.txt (line 3)) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.11.4->-r requirements.txt (line 3)) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.16.0->-r requirements.txt (line 2)) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from pandas->datasets==3.6.0->-r requirements.txt (line 5)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from pandas->datasets==3.6.0->-r requirements.txt (line 5)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from pandas->datasets==3.6.0->-r requirements.txt (line 5)) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==3.6.0->-r requirements.txt (line 5)) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%cd /home/ubuntu/environment/FineTuning/HuggingFaceExample/01_finetuning/assets\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning\n",
    "\n",
    "In this section, we fine-tune the Qwen3-1.7B model on the Text-to-SQL task using Hugging Face Optimum Neuron. Here are the parameters we are going to pass - \n",
    "\n",
    "1. `--nnodes`:\tNumber of nodes (1 = single node)\n",
    "2. `--nproc_per_node`: \tProcesses per node (usually equals number of devices).\n",
    "3. `--model_id, --tokenizer_id`:\tModel and tokenizer identifiers (from Hugging Face or local path).\n",
    "4. `--output_dir`:\tDirectory for saving checkpoints and logs.\n",
    "5. `--bf16`:\tEnables bfloat16 precision for faster, memory-efficient training.\n",
    "5. `--gradient_checkpointing`:\tSaves memory by recomputing activations during backprop.\n",
    "6. `--gradient_accumulation_steps`:\tSteps to accumulate gradients before optimizer update.\n",
    "7. `--learning_rate`:\tInitial training learning rate.\n",
    "8. `--max_steps`:\tTotal number of training steps.\n",
    "9. `--per_device_train_batch_size`:\tBatch size per device.\n",
    "10. `--tensor_parallel_size`:\tNumber of devices for tensor parallelism.\n",
    "11. `--lora_r, --lora_alpha, --lora_dropout`:\tLoRA hyperparameters â€” rank, scaling, and dropout rate.\n",
    "12. `--dataloader_drop_last`:\tDrops last incomplete batch.\n",
    "13. `--disable_tqdm`: Disables progress bar.\n",
    "14. `--logging_steps`:\tLog interval (in steps)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "2025-11-09 00:48:47.708260: W neuron/nrt_adaptor.cc:53] nrt_tensor_write_hugepage() is not available, will fall back to nrt_tensor_write().\n",
      "2025-11-09 00:48:47.708293: W neuron/nrt_adaptor.cc:62] nrt_tensor_read_hugepage() is not available, will fall back to nrt_tensor_read().\n",
      "2025-Nov-09 00:48:47.0710 121345:121389 [0] int nccl_net_ofi_create_plugin(nccl_net_ofi_plugin_t**):213 CCOM WARN NET/OFI Failed to initialize sendrecv protocol\n",
      "2025-Nov-09 00:48:47.0720 121345:121389 [0] int nccl_net_ofi_create_plugin(nccl_net_ofi_plugin_t**):354 CCOM WARN NET/OFI aws-ofi-nccl initialization failed\n",
      "2025-Nov-09 00:48:47.0730 121345:121389 [0] ncclResult_t nccl_net_ofi_init_no_atexit_fini_v6(ncclDebugLogger_t):183 CCOM WARN NET/OFI Initializing plugin failed\n",
      "2025-Nov-09 00:48:47.0740 121345:121389 [0] net_plugin.cc:97 CCOM WARN OFI plugin initNet() failed is EFA enabled?\n",
      "[2025-11-09 00:48:47.751: I neuronx_distributed/parallel_layers/parallel_state.py:628] > initializing tensor model parallel with size 1\n",
      "[2025-11-09 00:48:47.751: I neuronx_distributed/parallel_layers/parallel_state.py:629] > initializing pipeline model parallel with size 1\n",
      "[2025-11-09 00:48:47.751: I neuronx_distributed/parallel_layers/parallel_state.py:630] > initializing context model parallel with size 1\n",
      "[2025-11-09 00:48:47.751: I neuronx_distributed/parallel_layers/parallel_state.py:631] > initializing data parallel with size 1\n",
      "[2025-11-09 00:48:47.751: I neuronx_distributed/parallel_layers/parallel_state.py:632] > initializing world size to 1\n",
      "2025-11-09 00:48:47.000760:  121345  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.20.9961.0+0acef03a/MODULE_1017888704236904008+e30acd3a/model.neff\n",
      "[2025-11-09 00:48:47.768: I neuronx_distributed/parallel_layers/parallel_state.py:379] [rank_0_pp-1_tp-1_dp-1_cp-1] Chosen Logic for replica groups ret_logic=<PG_Group_Logic.LOGIC1: (<function ascending_ring_PG_group at 0x7cccc6eb72e0>, 'Ascending Ring PG Group')>\n",
      "[2025-11-09 00:48:47.769: I neuronx_distributed/parallel_layers/parallel_state.py:668] [rank_0_pp-1_tp-1_dp-1_cp-1] tp_groups: replica_groups.tp_groups=[[0]]\n",
      "[2025-11-09 00:48:47.769: I neuronx_distributed/parallel_layers/parallel_state.py:669] [rank_0_pp-1_tp-1_dp-1_cp-1] dp_groups: replica_groups.dp_groups=[[0]]\n",
      "[2025-11-09 00:48:47.769: I neuronx_distributed/parallel_layers/parallel_state.py:670] [rank_0_pp-1_tp-1_dp-1_cp-1] pp_groups: replica_groups.pp_groups=[[0]]\n",
      "[2025-11-09 00:48:47.769: I neuronx_distributed/parallel_layers/parallel_state.py:671] [rank_0_pp-1_tp-1_dp-1_cp-1] cp_groups: replica_groups.cp_groups=[[0]]\n",
      "[2025-11-09 00:48:47.769: I neuronx_distributed/parallel_layers/parallel_state.py:672] [rank_0_pp-1_tp-1_dp-1_cp-1] ep_model_groups: replica_groups.ep_model_groups=[[0]]\n",
      "[2025-11-09 00:48:47.769: I neuronx_distributed/parallel_layers/parallel_state.py:673] [rank_0_pp-1_tp-1_dp-1_cp-1] ep_data_groups: replica_groups.ep_data_groups=[[0]]\n",
      "torch.distributed process group is initialized, but parallel_mode != ParallelMode.DISTRIBUTED. In order to use Torch DDP, launch your script with `python -m torch.distributed.launch\n",
      "No Hugging Face token found in environment, checking AWS Secrets Manager...\n",
      "Logging in to Hugging Face Hub...\n",
      "train (2).jsonl: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36.8M/36.8M [00:01<00:00, 34.0MB/s]\n",
      "Generating train split: 100%|â–ˆâ–ˆ| 64000/64000 [00:00<00:00, 760369.30 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57600/57600 [00:03<00:00, 14803.09 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6400/6400 [00:00<00:00, 15006.19 examples/s]\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/optimum/neuron/models/inference/backend/modules/kvcache/kv_cache_manager.py:24: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from ..attention.gqa import (\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/optimum/neuron/models/inference/llama/modeling_llama.py:45: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from ..backend.modules.attention.attention_base import NeuronAttentionBase\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:596: UserWarning: `sequence_parallel_enabled` is set to `True`, but got world_size of 1\n",
      "  warnings.warn(f\"`sequence_parallel_enabled` is set to `True`, but got world_size of {world_size}\")\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.15it/s]\n",
      "torch.distributed process group is initialized, but parallel_mode != ParallelMode.DISTRIBUTED. In order to use Torch DDP, launch your script with `python -m torch.distributed.launch\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/transformers/training_args.py:2058: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of ðŸ¤— Transformers. Use `--hub_token` instead.\n",
      "  warnings.warn(\n",
      "Generating train split: 9785 examples [00:15, 616.65 examples/s]\n",
      "Generating train split: 1088 examples [00:01, 641.19 examples/s]\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/optimum/neuron/trainers.py:1467: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `NeuronSFTTrainer.__init__`. Use `processing_class` instead.\n",
      "  return Trainer.__init__(self, *args, **kwargs)\n",
      "No label_names provided for model class `NeuronPeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/optimum/neuron/trainers.py:1726: UserWarning: You passed `packing=True` to the SFTTrainer/SFTConfig, and you are training your model with `max_steps` strategy. The dataset will be iterated until the `max_steps` are reached.\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 9,785\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 2\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 0\n",
      "  Total optimization steps = 1,000\n",
      "  Number of trainable parameters = 16,515,072\n",
      "2025-11-09 00:49:23.000848:  121345  INFO ||NEURON_CC_WRAPPER||: Using a cached neff at /var/tmp/neuron-compile-cache/neuronxcc-2.20.9961.0+0acef03a/MODULE_17150802957188818040+a3455b04/model.neff\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:485: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "[rank0]: Traceback (most recent call last):\n",
      "[rank0]:   File \"/home/ubuntu/environment/FineTuning/HuggingFaceExample/01_finetuning/assets/finetune_model.py\", line 323, in <module>\n",
      "[rank0]:     training_function(script_args, training_args)\n",
      "[rank0]:   File \"/home/ubuntu/environment/FineTuning/HuggingFaceExample/01_finetuning/assets/finetune_model.py\", line 243, in training_function\n",
      "[rank0]:     trainer.train()\n",
      "[rank0]:   File \"/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/optimum/neuron/trainers.py\", line 1745, in train\n",
      "[rank0]:     output = super().train(*args, **kwargs)\n",
      "[rank0]:   File \"/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/optimum/neuron/trainers.py\", line 1395, in train\n",
      "[rank0]:     result = super().train(\n",
      "[rank0]:   File \"/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/trl/trainer/sft_trainer.py\", line 434, in train\n",
      "[rank0]:     output = super().train(*args, **kwargs)\n",
      "[rank0]:   File \"/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/transformers/trainer.py\", line 2245, in train\n",
      "[rank0]:     return inner_training_loop(\n",
      "[rank0]:   File \"/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/optimum/neuron/trainers.py\", line 1007, in _inner_training_loop\n",
      "[rank0]:     tr_loss_step = self.training_step(model, inputs, num_items_in_batch)\n",
      "[rank0]:   File \"/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/optimum/neuron/trainers.py\", line 465, in training_step\n",
      "[rank0]:     loss = super().training_step(model, inputs, num_items_in_batch=num_items_in_batch)\n",
      "[rank0]:   File \"/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/transformers/trainer.py\", line 3736, in training_step\n",
      "[rank0]:     loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)\n",
      "[rank0]:   File \"/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/optimum/neuron/trainers.py\", line 427, in compute_loss\n",
      "[rank0]:     loss = super().compute_loss(\n",
      "[rank0]:   File \"/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/transformers/trainer.py\", line 3801, in compute_loss\n",
      "[rank0]:     outputs = model(**inputs)\n",
      "[rank0]:   File \"/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "[rank0]:     return self._call_impl(*args, **kwargs)\n",
      "[rank0]:   File \"/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "[rank0]:     return forward_call(*args, **kwargs)\n",
      "[rank0]:   File \"/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/peft/peft_model.py\", line 878, in forward\n",
      "[rank0]:     return self.get_base_model()(*args, **kwargs)\n",
      "[rank0]:   File \"/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "[rank0]:     return self._call_impl(*args, **kwargs)\n",
      "[rank0]:   File \"/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "[rank0]:     return forward_call(*args, **kwargs)\n",
      "[rank0]:   File \"/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/transformers/utils/generic.py\", line 965, in wrapper\n",
      "[rank0]:     output = func(self, *args, **kwargs)\n",
      "[rank0]:   File \"/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/optimum/neuron/models/training/llama/modeling_llama.py\", line 884, in forward\n",
      "[rank0]:     outputs = self.model(\n",
      "[rank0]:   File \"/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "[rank0]:     return self._call_impl(*args, **kwargs)\n",
      "[rank0]:   File \"/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "[rank0]:     return forward_call(*args, **kwargs)\n",
      "[rank0]:   File \"/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/transformers/utils/generic.py\", line 965, in wrapper\n",
      "[rank0]:     output = func(self, *args, **kwargs)\n",
      "[rank0]:   File \"/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/optimum/neuron/models/training/llama/modeling_llama.py\", line 707, in forward\n",
      "[rank0]:     layer_outputs = checkpoint(\n",
      "[rank0]:   File \"/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/torch_xla/utils/checkpoint.py\", line 302, in checkpoint\n",
      "[rank0]:     return CheckpointFunction.apply(function, preserve, *args)\n",
      "[rank0]:   File \"/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/torch/autograd/function.py\", line 575, in apply\n",
      "[rank0]:     return super().apply(*args, **kwargs)  # type: ignore[misc]\n",
      "[rank0]:   File \"/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/torch_xla/utils/checkpoint.py\", line 139, in forward\n",
      "[rank0]:     outputs = run_function(*args)\n",
      "[rank0]:   File \"/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "[rank0]:     return self._call_impl(*args, **kwargs)\n",
      "[rank0]:   File \"/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "[rank0]:     return forward_call(*args, **kwargs)\n",
      "[rank0]:   File \"/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/optimum/neuron/models/training/llama/modeling_llama.py\", line 563, in forward\n",
      "[rank0]:     hidden_states, self_attn_weights = self.self_attn(\n",
      "[rank0]:   File \"/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1751, in _wrapped_call_impl\n",
      "[rank0]:     return self._call_impl(*args, **kwargs)\n",
      "[rank0]:   File \"/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1762, in _call_impl\n",
      "[rank0]:     return forward_call(*args, **kwargs)\n",
      "[rank0]:   File \"/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/optimum/neuron/models/training/qwen3/modeling_qwen3.py\", line 125, in forward\n",
      "[rank0]:     query_states, key_states = apply_rotary_pos_emb(\n",
      "[rank0]:   File \"/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/optimum/neuron/models/training/llama/modeling_llama.py\", line 171, in apply_rotary_pos_emb\n",
      "[rank0]:     q_embed = (q * cos) + (rotate_half(q, flash_attn, transpose_nki_inputs) * sin)\n",
      "[rank0]: RuntimeError: torch_xla/csrc/helpers.cpp:619 : Check failed: dim1 == dim2 || dim1 == 1 || dim2 == 1 || dim1 == xla::Shape::kUnboundedSize || dim2 == xla::Shape::kUnboundedSize \n",
      "[rank0]: *** Begin stack trace ***\n",
      "[rank0]: \ttsl::CurrentStackTrace[abi:cxx11]()\n",
      "[rank0]: \ttorch_xla::XlaHelpers::GetPromotedShape(xla::Shape const&, xla::Shape const&)\n",
      "[rank0]: \ttorch_xla::XlaHelpers::PromoteShapes(xla::XlaOp, xla::XlaOp)\n",
      "[rank0]: \ttorch_xla::XlaHelpers::Promote(xla::XlaOp, xla::XlaOp)\n",
      "[rank0]: \ttorch_xla::BuildMul(xla::XlaOp, xla::XlaOp)\n",
      "[rank0]: \t\n",
      "[rank0]: \ttorch_xla::InferOutputShape(absl::lts_20230802::Span<xla::Shape const>, std::function<xla::XlaOp (absl::lts_20230802::Span<xla::XlaOp const>)> const&)\n",
      "[rank0]: \t\n",
      "[rank0]: \t\n",
      "[rank0]: \ttorch_xla::XlaNode::GetOpShape(std::function<xla::Shape ()> const&) const\n",
      "[rank0]: \ttorch_xla::XlaNode::XlaNode(torch::lazy::OpKind, c10::ArrayRef<torch::lazy::Value>, std::function<xla::Shape ()> const&, unsigned long, torch::lazy::hash_t)\n",
      "[rank0]: \ttorch_xla::Generic::Generic(torch::lazy::OpKind, c10::ArrayRef<torch::lazy::Value>, std::function<xla::Shape ()> const&, std::function<absl::lts_20230802::InlinedVector<xla::XlaOp, 1ul, std::allocator<xla::XlaOp> > (torch_xla::XlaNode const&, torch_xla::LoweringContext*)>, unsigned long, torch::lazy::hash_t)\n",
      "[rank0]: \tstd::shared_ptr<torch::lazy::Node> torch_xla::MakeNode<torch_xla::Generic, torch::lazy::OpKind, c10::ArrayRef<torch::lazy::Value>&, std::function<xla::Shape ()> const&, std::function<absl::lts_20230802::InlinedVector<xla::XlaOp, 1ul, std::allocator<xla::XlaOp> > (torch_xla::XlaNode const&, torch_xla::LoweringContext*)>, unsigned long&, torch::lazy::hash_t&>(torch::lazy::OpKind&&, c10::ArrayRef<torch::lazy::Value>&, std::function<xla::Shape ()> const&, std::function<absl::lts_20230802::InlinedVector<xla::XlaOp, 1ul, std::allocator<xla::XlaOp> > (torch_xla::XlaNode const&, torch_xla::LoweringContext*)>&&, unsigned long&, torch::lazy::hash_t&)\n",
      "[rank0]: \ttorch_xla::Mul(torch::lazy::Value const&, torch::lazy::Value const&)\n",
      "[rank0]: \ttorch_xla::tensor_methods::mul(c10::intrusive_ptr<torch_xla::XLATensor, c10::detail::intrusive_target_default_null_type<torch_xla::XLATensor> > const&, c10::intrusive_ptr<torch_xla::XLATensor, c10::detail::intrusive_target_default_null_type<torch_xla::XLATensor> > const&, std::optional<c10::ScalarType>)\n",
      "[rank0]: \t\n",
      "[rank0]: \ttorch_xla::XLANativeFunctions::mul(at::Tensor const&, at::Tensor const&)\n",
      "[rank0]: \t\n",
      "[rank0]: \tat::_ops::mul_Tensor::redispatch(c10::DispatchKeySet, at::Tensor const&, at::Tensor const&)\n",
      "[rank0]: \t\n",
      "[rank0]: \t\n",
      "[rank0]: \tat::_ops::mul_Tensor::call(at::Tensor const&, at::Tensor const&)\n",
      "[rank0]: \t\n",
      "[rank0]: \t\n",
      "[rank0]: \t\n",
      "[rank0]: \t\n",
      "[rank0]: \t\n",
      "[rank0]: \t\n",
      "[rank0]: \tPyNumber_Multiply\n",
      "[rank0]: \t_PyEval_EvalFrameDefault\n",
      "[rank0]: \t_PyFunction_Vectorcall\n",
      "[rank0]: \t_PyEval_EvalFrameDefault\n",
      "[rank0]: \t\n",
      "[rank0]: \tPyObject_Call\n",
      "[rank0]: \t_PyEval_EvalFrameDefault\n",
      "[rank0]: \t\n",
      "[rank0]: \tPyObject_Call\n",
      "[rank0]: \t_PyEval_EvalFrameDefault\n",
      "[rank0]: \t_PyFunction_Vectorcall\n",
      "[rank0]: \t_PyObject_FastCallDictTstate\n",
      "[rank0]: \t_PyObject_Call_Prepend\n",
      "[rank0]: \t\n",
      "[rank0]: \tPyObject_Call\n",
      "[rank0]: \t_PyEval_EvalFrameDefault\n",
      "[rank0]: \t\n",
      "[rank0]: \t_PyEval_EvalFrameDefault\n",
      "[rank0]: \t\n",
      "[rank0]: \t_PyEval_EvalFrameDefault\n",
      "[rank0]: \t\n",
      "[rank0]: \t_PyEval_EvalFrameDefault\n",
      "[rank0]: \t_PyFunction_Vectorcall\n",
      "[rank0]: \t\n",
      "[rank0]: \t\n",
      "[rank0]: \tPyObject_Call\n",
      "[rank0]: \t_PyEval_EvalFrameDefault\n",
      "[rank0]: \t\n",
      "[rank0]: \t_PyEval_EvalFrameDefault\n",
      "[rank0]: \t_PyFunction_Vectorcall\n",
      "[rank0]: \t_PyEval_EvalFrameDefault\n",
      "[rank0]: \t_PyFunction_Vectorcall\n",
      "[rank0]: \tPyObject_Call\n",
      "[rank0]: \t_PyEval_EvalFrameDefault\n",
      "[rank0]: \t\n",
      "[rank0]: \tPyObject_Call\n",
      "[rank0]: \t_PyEval_EvalFrameDefault\n",
      "[rank0]: \t\n",
      "[rank0]: \tPyObject_Call\n",
      "[rank0]: \t_PyEval_EvalFrameDefault\n",
      "[rank0]: \t_PyFunction_Vectorcall\n",
      "[rank0]: \t_PyObject_FastCallDictTstate\n",
      "[rank0]: \t_PyObject_Call_Prepend\n",
      "[rank0]: \t\n",
      "[rank0]: \tPyObject_Call\n",
      "[rank0]: \t_PyEval_EvalFrameDefault\n",
      "[rank0]: \t_PyFunction_Vectorcall\n",
      "[rank0]: \tPyObject_Call\n",
      "[rank0]: \t_PyEval_EvalFrameDefault\n",
      "[rank0]: \t\n",
      "[rank0]: \tPyObject_Call\n",
      "[rank0]: \t_PyEval_EvalFrameDefault\n",
      "[rank0]: \t\n",
      "[rank0]: \tPyObject_Call\n",
      "[rank0]: \t_PyEval_EvalFrameDefault\n",
      "[rank0]: \t_PyFunction_Vectorcall\n",
      "[rank0]: \t_PyObject_FastCallDictTstate\n",
      "[rank0]: \t_PyObject_Call_Prepend\n",
      "[rank0]: \t\n",
      "[rank0]: \tPyObject_Call\n",
      "[rank0]: \t_PyEval_EvalFrameDefault\n",
      "[rank0]: \t\n",
      "[rank0]: \tPyObject_Call\n",
      "[rank0]: \t_PyEval_EvalFrameDefault\n",
      "[rank0]: \t\n",
      "[rank0]: \tPyObject_Call\n",
      "[rank0]: \t_PyEval_EvalFrameDefault\n",
      "[rank0]: \t_PyFunction_Vectorcall\n",
      "[rank0]: \t_PyObject_FastCallDictTstate\n",
      "[rank0]: \t_PyObject_Call_Prepend\n",
      "[rank0]: \t\n",
      "[rank0]: \tPyObject_Call\n",
      "[rank0]: \t_PyEval_EvalFrameDefault\n",
      "[rank0]: \t\n",
      "[rank0]: \t_PyEval_EvalFrameDefault\n",
      "[rank0]: \t\n",
      "[rank0]: \t_PyEval_EvalFrameDefault\n",
      "[rank0]: \t\n",
      "[rank0]: \t_PyEval_EvalFrameDefault\n",
      "[rank0]: \t_PyFunction_Vectorcall\n",
      "[rank0]: \t_PyEval_EvalFrameDefault\n",
      "[rank0]: \t\n",
      "[rank0]: \tPyObject_Call\n",
      "[rank0]: \t\n",
      "[rank0]: \t_PyObject_MakeTpCall\n",
      "[rank0]: \t_PyEval_EvalFrameDefault\n",
      "[rank0]: \t\n",
      "[rank0]: \tPyObject_Call\n",
      "[rank0]: \t_PyEval_EvalFrameDefault\n",
      "[rank0]: \t\n",
      "[rank0]: \tPyObject_Call\n",
      "[rank0]: \t_PyEval_EvalFrameDefault\n",
      "[rank0]: \t\n",
      "[rank0]: \t_PyEval_EvalFrameDefault\n",
      "[rank0]: \t_PyFunction_Vectorcall\n",
      "[rank0]: \t_PyEval_EvalFrameDefault\n",
      "[rank0]: \t_PyFunction_Vectorcall\n",
      "[rank0]: \t_PyEval_EvalFrameDefault\n",
      "[rank0]: \t\n",
      "[rank0]: \tPyEval_EvalCode\n",
      "[rank0]: *** End stack trace ***\n",
      "\n",
      "E1109 00:49:25.831000 121336 /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py:874] failed (exitcode: 1) local_rank: 0 (pid: 121345) of binary: /opt/aws_neuronx_venv_pytorch_latest/bin/python\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/aws_neuronx_venv_pytorch_latest/bin/torchrun\", line 7, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 355, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/torch/distributed/run.py\", line 892, in main\n",
      "    run(args)\n",
      "  File \"/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/torch/distributed/run.py\", line 883, in run\n",
      "    elastic_launch(\n",
      "  File \"/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 139, in __call__\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\n",
      "  File \"/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 270, in launch_agent\n",
      "    raise ChildFailedError(\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
      "============================================================\n",
      "finetune_model.py FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "  <NO_OTHER_FAILURES>\n",
      "------------------------------------------------------------\n",
      "Root Cause (first observed failure):\n",
      "[0]:\n",
      "  time      : 2025-11-09_00:49:25\n",
      "  host      : ip-192-168-0-202.us-west-2.compute.internal\n",
      "  rank      : 0 (local_rank: 0)\n",
      "  exitcode  : 1 (pid: 121345)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "!torchrun \\\n",
    "  --nnodes 1 \\\n",
    "  --nproc_per_node 1 \\\n",
    "  finetune_model.py \\\n",
    "  --model_id Qwen/Qwen3-1.7B \\\n",
    "  --tokenizer_id Qwen/Qwen3-1.7B \\\n",
    "  --output_dir ~/environment/ml/qwen \\\n",
    "  --bf16 True \\\n",
    "  --gradient_checkpointing True \\\n",
    "  --gradient_accumulation_steps 1 \\\n",
    "  --learning_rate 5e-5 \\\n",
    "  --max_steps 1000 \\\n",
    "  --per_device_train_batch_size 2 \\\n",
    "  --tensor_parallel_size 2 \\\n",
    "  --lora_r 16 \\\n",
    "  --lora_alpha 32 \\\n",
    "  --lora_dropout 0.05 \\\n",
    "  --dataloader_drop_last True \\\n",
    "  --disable_tqdm True \\\n",
    "  --logging_steps 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compilation\n",
    "\n",
    "After completing the fine-tuning process, the next step is to compile the trained model for AWS Trainium inference using the Hugging Face Optimum Neuron toolchain.\n",
    "Neuron compilation optimizes the model graph and converts it into a Neuron Executable File Format (NEFF), enabling efficient execution on NeuronCores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/optimum/commands/env.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import get_distribution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/parallel_layers/layers.py:14: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  from .mappings import (\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/neuronx_distributed/modules/moe/blockwise.py:42: DeprecationWarning: torch_neuronx.nki_jit is deprecated, use nki.jit instead.\n",
      "  component, error = import_nki(config)\n",
      "/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/optimum/commands/env.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import get_distribution\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/optimum/exporters/neuron/__main__.py\", line 856, in <module>\n",
      "    main()\n",
      "  File \"/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/optimum/exporters/neuron/__main__.py\", line 794, in main\n",
      "    library_name = TasksManager.infer_library_from_model(args.model, cache_dir=args.cache_dir)\n",
      "  File \"/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/optimum/exporters/tasks.py\", line 2055, in infer_library_from_model\n",
      "    library_name = cls._infer_library_from_model_name_or_path(\n",
      "  File \"/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/optimum/exporters/tasks.py\", line 1983, in _infer_library_from_model_name_or_path\n",
      "    all_files, _ = TasksManager.get_model_files(\n",
      "  File \"/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/optimum/exporters/tasks.py\", line 1611, in get_model_files\n",
      "    all_files = huggingface_hub.list_repo_files(\n",
      "  File \"/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py\", line 106, in _inner_fn\n",
      "    validate_repo_id(arg_value)\n",
      "  File \"/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py\", line 154, in validate_repo_id\n",
      "    raise HFValidationError(\n",
      "huggingface_hub.errors.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/home/ubuntu/environment/ml/qwen/merged_model'. Use `repo_type` argument if needed.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/aws_neuronx_venv_pytorch_latest/bin/optimum-cli\", line 7, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/optimum/commands/optimum_cli.py\", line 208, in main\n",
      "    service.run()\n",
      "  File \"/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/optimum/commands/export/neuronx.py\", line 326, in run\n",
      "    subprocess.run(full_command, shell=True, check=True)\n",
      "  File \"/usr/lib/python3.10/subprocess.py\", line 526, in run\n",
      "    raise CalledProcessError(retcode, process.args,\n",
      "subprocess.CalledProcessError: Command 'python3 -m optimum.exporters.neuron --model /home/ubuntu/environment/ml/qwen/merged_model --task text-generation --sequence_length 512 --batch_size 1 /home/ubuntu/environment/ml/qwen/compiled_model' returned non-zero exit status 1.\n"
     ]
    }
   ],
   "source": [
    "!optimum-cli export neuron \\\n",
    "  --model /home/ubuntu/environment/ml/qwen/merged_model \\\n",
    "  --task text-generation \\\n",
    "  --sequence_length 512 \\\n",
    "  --batch_size 1 \\\n",
    "  /home/ubuntu/environment/ml/qwen/compiled_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "\n",
    "We will install the Optimum Neuron vllm library.  Then, run inference using the compiled model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: optimum-neuron[vllm] in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (0.3.0)\n",
      "Requirement already satisfied: transformers~=4.51.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from optimum-neuron[vllm]) (4.51.3)\n",
      "Requirement already satisfied: accelerate==1.8.1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from optimum-neuron[vllm]) (1.8.1)\n",
      "Requirement already satisfied: optimum~=1.24.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from optimum-neuron[vllm]) (1.24.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.29.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from optimum-neuron[vllm]) (0.33.4)\n",
      "Requirement already satisfied: numpy<=1.25.2,>=1.22.2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from optimum-neuron[vllm]) (1.25.2)\n",
      "Requirement already satisfied: protobuf<4,>=3.20.3 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from optimum-neuron[vllm]) (3.20.3)\n",
      "Requirement already satisfied: vllm==0.9.2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from optimum-neuron[vllm]) (0.9.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from accelerate==1.8.1->optimum-neuron[vllm]) (24.2)\n",
      "Requirement already satisfied: psutil in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from accelerate==1.8.1->optimum-neuron[vllm]) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from accelerate==1.8.1->optimum-neuron[vllm]) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from accelerate==1.8.1->optimum-neuron[vllm]) (2.7.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from accelerate==1.8.1->optimum-neuron[vllm]) (0.5.3)\n",
      "Requirement already satisfied: regex in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (2025.7.34)\n",
      "Requirement already satisfied: cachetools in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (6.2.1)\n",
      "Requirement already satisfied: sentencepiece in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (0.2.0)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (2.32.4)\n",
      "Requirement already satisfied: tqdm in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (4.67.1)\n",
      "Requirement already satisfied: blake3 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (1.0.8)\n",
      "Requirement already satisfied: py-cpuinfo in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (9.0.0)\n",
      "Requirement already satisfied: tokenizers>=0.21.1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (0.21.4)\n",
      "Requirement already satisfied: fastapi>=0.115.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm]) (0.116.1)\n",
      "Requirement already satisfied: aiohttp in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (3.12.15)\n",
      "Requirement already satisfied: openai<=1.90.0,>=1.52.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (1.90.0)\n",
      "Requirement already satisfied: pydantic>=2.10 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (2.11.7)\n",
      "Requirement already satisfied: prometheus_client>=0.18.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (0.22.1)\n",
      "Requirement already satisfied: pillow in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (11.3.0)\n",
      "Requirement already satisfied: prometheus-fastapi-instrumentator>=7.0.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (7.1.0)\n",
      "Requirement already satisfied: tiktoken>=0.6.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (0.12.0)\n",
      "Requirement already satisfied: lm-format-enforcer<0.11,>=0.10.11 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (0.10.12)\n",
      "Requirement already satisfied: llguidance<0.8.0,>=0.7.11 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (0.7.30)\n",
      "Requirement already satisfied: outlines==0.1.11 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (0.1.11)\n",
      "Requirement already satisfied: lark==1.2.2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (1.2.2)\n",
      "Requirement already satisfied: xgrammar==0.1.19 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (0.1.19)\n",
      "Requirement already satisfied: typing_extensions>=4.10 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (4.14.1)\n",
      "Requirement already satisfied: filelock>=3.16.1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (3.18.0)\n",
      "Requirement already satisfied: partial-json-parser in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (0.2.1.1.post6)\n",
      "Requirement already satisfied: pyzmq>=25.0.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (27.0.0)\n",
      "Requirement already satisfied: msgspec in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (0.19.0)\n",
      "Requirement already satisfied: gguf>=0.13.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (0.17.1)\n",
      "Requirement already satisfied: mistral_common>=1.6.2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from mistral_common[opencv]>=1.6.2->vllm==0.9.2->optimum-neuron[vllm]) (1.8.5)\n",
      "Requirement already satisfied: opencv-python-headless>=4.11.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (4.11.0.86)\n",
      "Requirement already satisfied: einops in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (0.8.1)\n",
      "Requirement already satisfied: compressed-tensors==0.10.2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (0.10.2)\n",
      "Requirement already satisfied: depyf==0.18.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (0.18.0)\n",
      "Requirement already satisfied: cloudpickle in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (3.1.1)\n",
      "Requirement already satisfied: watchfiles in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (1.1.1)\n",
      "Requirement already satisfied: python-json-logger in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (3.3.0)\n",
      "Requirement already satisfied: scipy in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (1.12.0)\n",
      "Requirement already satisfied: ninja in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (1.13.0)\n",
      "Requirement already satisfied: pybase64 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (1.4.2)\n",
      "Requirement already satisfied: numba==0.61.2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (0.61.2)\n",
      "Requirement already satisfied: ray!=2.44.*,>=2.43.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from ray[cgraph]!=2.44.*,>=2.43.0->vllm==0.9.2->optimum-neuron[vllm]) (2.51.1)\n",
      "Requirement already satisfied: torchaudio==2.7.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (2.7.0)\n",
      "Requirement already satisfied: torchvision==0.22.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (0.22.0)\n",
      "Requirement already satisfied: xformers==0.0.30 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from vllm==0.9.2->optimum-neuron[vllm]) (0.0.30)\n",
      "Requirement already satisfied: astor in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from depyf==0.18.0->vllm==0.9.2->optimum-neuron[vllm]) (0.8.1)\n",
      "Requirement already satisfied: dill in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from depyf==0.18.0->vllm==0.9.2->optimum-neuron[vllm]) (0.3.8)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from numba==0.61.2->vllm==0.9.2->optimum-neuron[vllm]) (0.44.0)\n",
      "Requirement already satisfied: interegular in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from outlines==0.1.11->vllm==0.9.2->optimum-neuron[vllm]) (0.3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from outlines==0.1.11->vllm==0.9.2->optimum-neuron[vllm]) (3.1.6)\n",
      "Requirement already satisfied: nest_asyncio in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from outlines==0.1.11->vllm==0.9.2->optimum-neuron[vllm]) (1.6.0)\n",
      "Requirement already satisfied: diskcache in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from outlines==0.1.11->vllm==0.9.2->optimum-neuron[vllm]) (5.6.3)\n",
      "Requirement already satisfied: referencing in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from outlines==0.1.11->vllm==0.9.2->optimum-neuron[vllm]) (0.36.2)\n",
      "Requirement already satisfied: jsonschema in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from outlines==0.1.11->vllm==0.9.2->optimum-neuron[vllm]) (4.25.0)\n",
      "Requirement already satisfied: pycountry in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from outlines==0.1.11->vllm==0.9.2->optimum-neuron[vllm]) (24.6.1)\n",
      "Requirement already satisfied: airportsdata in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from outlines==0.1.11->vllm==0.9.2->optimum-neuron[vllm]) (20250909)\n",
      "Requirement already satisfied: outlines_core==0.1.26 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from outlines==0.1.11->vllm==0.9.2->optimum-neuron[vllm]) (0.1.26)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (2.8.8)\n",
      "Requirement already satisfied: fsspec in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (3.3.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from triton==3.3.0->torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (80.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from openai<=1.90.0,>=1.52.0->vllm==0.9.2->optimum-neuron[vllm]) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from openai<=1.90.0,>=1.52.0->vllm==0.9.2->optimum-neuron[vllm]) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from openai<=1.90.0,>=1.52.0->vllm==0.9.2->optimum-neuron[vllm]) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from openai<=1.90.0,>=1.52.0->vllm==0.9.2->optimum-neuron[vllm]) (0.11.1)\n",
      "Requirement already satisfied: sniffio in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from openai<=1.90.0,>=1.52.0->vllm==0.9.2->optimum-neuron[vllm]) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<=1.90.0,>=1.52.0->vllm==0.9.2->optimum-neuron[vllm]) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<=1.90.0,>=1.52.0->vllm==0.9.2->optimum-neuron[vllm]) (3.10)\n",
      "Requirement already satisfied: certifi in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<=1.90.0,>=1.52.0->vllm==0.9.2->optimum-neuron[vllm]) (2025.7.14)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<=1.90.0,>=1.52.0->vllm==0.9.2->optimum-neuron[vllm]) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<=1.90.0,>=1.52.0->vllm==0.9.2->optimum-neuron[vllm]) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from pydantic>=2.10->vllm==0.9.2->optimum-neuron[vllm]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from pydantic>=2.10->vllm==0.9.2->optimum-neuron[vllm]) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from pydantic>=2.10->vllm==0.9.2->optimum-neuron[vllm]) (0.4.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from huggingface-hub>=0.29.0->optimum-neuron[vllm]) (1.2.0)\n",
      "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from fastapi>=0.115.0->fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm]) (0.47.2)\n",
      "Requirement already satisfied: fastapi-cli>=0.0.8 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm]) (0.0.14)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm]) (0.0.20)\n",
      "Requirement already satisfied: email-validator>=2.0.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm]) (2.3.0)\n",
      "Requirement already satisfied: uvicorn>=0.12.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm]) (0.38.0)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from email-validator>=2.0.0->fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm]) (2.8.0)\n",
      "Requirement already satisfied: typer>=0.15.1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm]) (0.20.0)\n",
      "Requirement already satisfied: rich-toolkit>=0.14.8 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm]) (0.15.1)\n",
      "Requirement already satisfied: fastapi-cloud-cli>=0.1.1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm]) (0.3.1)\n",
      "Requirement already satisfied: rignore>=0.5.1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm]) (0.7.6)\n",
      "Requirement already satisfied: sentry-sdk>=2.20.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from fastapi-cloud-cli>=0.1.1->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm]) (2.43.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from jinja2->outlines==0.1.11->vllm==0.9.2->optimum-neuron[vllm]) (3.0.2)\n",
      "Requirement already satisfied: pydantic-extra-types>=2.10.5 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from pydantic-extra-types[pycountry]>=2.10.5->mistral_common>=1.6.2->mistral_common[opencv]>=1.6.2->vllm==0.9.2->optimum-neuron[vllm]) (2.10.6)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from jsonschema->outlines==0.1.11->vllm==0.9.2->optimum-neuron[vllm]) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from jsonschema->outlines==0.1.11->vllm==0.9.2->optimum-neuron[vllm]) (2025.4.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from jsonschema->outlines==0.1.11->vllm==0.9.2->optimum-neuron[vllm]) (0.26.0)\n",
      "Requirement already satisfied: click!=8.3.0,>=7.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from ray!=2.44.*,>=2.43.0->ray[cgraph]!=2.44.*,>=2.43.0->vllm==0.9.2->optimum-neuron[vllm]) (8.2.1)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from ray!=2.44.*,>=2.43.0->ray[cgraph]!=2.44.*,>=2.43.0->vllm==0.9.2->optimum-neuron[vllm]) (1.1.2)\n",
      "Requirement already satisfied: cupy-cuda12x in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from ray[cgraph]!=2.44.*,>=2.43.0->vllm==0.9.2->optimum-neuron[vllm]) (13.6.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from requests>=2.26.0->vllm==0.9.2->optimum-neuron[vllm]) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from requests>=2.26.0->vllm==0.9.2->optimum-neuron[vllm]) (2.5.0)\n",
      "Requirement already satisfied: rich>=13.7.1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm]) (14.1.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm]) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm]) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit>=0.14.8->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm]) (0.1.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate==1.8.1->optimum-neuron[vllm]) (1.3.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from typer>=0.15.1->fastapi-cli>=0.0.8->fastapi-cli[standard]>=0.0.8; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm]) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm]) (0.7.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm]) (1.2.1)\n",
      "Requirement already satisfied: uvloop>=0.15.1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm]) (0.22.1)\n",
      "Requirement already satisfied: websockets>=10.4 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]>=0.115.0->vllm==0.9.2->optimum-neuron[vllm]) (15.0.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from aiohttp->vllm==0.9.2->optimum-neuron[vllm]) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from aiohttp->vllm==0.9.2->optimum-neuron[vllm]) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from aiohttp->vllm==0.9.2->optimum-neuron[vllm]) (5.0.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from aiohttp->vllm==0.9.2->optimum-neuron[vllm]) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from aiohttp->vllm==0.9.2->optimum-neuron[vllm]) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from aiohttp->vllm==0.9.2->optimum-neuron[vllm]) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from aiohttp->vllm==0.9.2->optimum-neuron[vllm]) (1.20.1)\n",
      "Requirement already satisfied: fastrlock>=0.5 in /opt/aws_neuronx_venv_pytorch_2_7_nxd_inference/lib/python3.10/site-packages (from cupy-cuda12x->ray[cgraph]!=2.44.*,>=2.43.0->vllm==0.9.2->optimum-neuron[vllm]) (0.8.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install optimum-neuron[vllm]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for ModelConfig\n  Value error, Invalid repository ID or local directory specified: '/home/ubuntu/environment/ml/qwen/compiled_model'.\nPlease verify the following requirements:\n1. Provide a valid Hugging Face repository ID.\n2. Specify a local directory that contains a recognized configuration file.\n   - For Hugging Face models: ensure the presence of a 'config.json'.\n   - For Mistral models: ensure the presence of a 'params.json'.\n3. For GGUF: pass the local path of the GGUF checkpoint.\n   Loading GGUF from a remote repo directly is not yet supported.\n [type=value_error, input_value=ArgsKwargs((), {'model': ...attention_dtype': None}), input_type=ArgsKwargs]\n    For further information visit https://errors.pydantic.dev/2.11/v/value_error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mvllm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LLM, SamplingParams\n\u001b[0;32m----> 3\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mLLM\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/ubuntu/environment/ml/qwen/compiled_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#local compiled model\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_num_seqs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_model_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2048\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mneuron\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensor_parallel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverride_neuron_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m example1\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124m<|im_start|>system\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124mYou are a task management assistant. Users conversationally discuss their activities with you. From their input, output a 1-2 sentence summary.<|im_end|>\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124m<|im_start|>assistant\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     17\u001b[0m example2\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124m<|im_start|>system\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124mYou are a task management assistant. Users conversationally discuss their activities with you. From their input, output a 1-2 sentence summary.<|im_end|>\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124m<|im_start|>assistant\u001b[39m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n",
      "File \u001b[0;32m/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/vllm/entrypoints/llm.py:271\u001b[0m, in \u001b[0;36mLLM.__init__\u001b[0;34m(self, model, task, tokenizer, tokenizer_mode, skip_tokenizer_init, trust_remote_code, allowed_local_media_path, tensor_parallel_size, dtype, quantization, revision, tokenizer_revision, seed, gpu_memory_utilization, swap_space, cpu_offload_gb, enforce_eager, max_seq_len_to_capture, disable_custom_all_reduce, disable_async_output_proc, hf_token, hf_overrides, mm_processor_kwargs, override_pooler_config, compilation_config, **kwargs)\u001b[0m\n\u001b[1;32m    241\u001b[0m engine_args \u001b[38;5;241m=\u001b[39m EngineArgs(\n\u001b[1;32m    242\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    243\u001b[0m     task\u001b[38;5;241m=\u001b[39mtask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    268\u001b[0m )\n\u001b[1;32m    270\u001b[0m \u001b[38;5;66;03m# Create the Engine (autoselects V0 vs V1)\u001b[39;00m\n\u001b[0;32m--> 271\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_engine \u001b[38;5;241m=\u001b[39m \u001b[43mLLMEngine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_engine_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musage_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mUsageContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLLM_CLASS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_engine)\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_counter \u001b[38;5;241m=\u001b[39m Counter()\n",
      "File \u001b[0;32m/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/vllm/engine/llm_engine.py:494\u001b[0m, in \u001b[0;36mLLMEngine.from_engine_args\u001b[0;34m(cls, engine_args, usage_context, stat_loggers)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates an LLM engine from the engine arguments.\"\"\"\u001b[39;00m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;66;03m# Create the engine configs.\u001b[39;00m\n\u001b[0;32m--> 494\u001b[0m vllm_config \u001b[38;5;241m=\u001b[39m \u001b[43mengine_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_engine_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43musage_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    496\u001b[0m engine_cls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m envs\u001b[38;5;241m.\u001b[39mVLLM_USE_V1:\n",
      "File \u001b[0;32m/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/vllm/engine/arg_utils.py:1067\u001b[0m, in \u001b[0;36mEngineArgs.create_engine_config\u001b[0;34m(self, usage_context)\u001b[0m\n\u001b[1;32m   1063\u001b[0m current_platform\u001b[38;5;241m.\u001b[39mpre_register_and_update()\n\u001b[1;32m   1065\u001b[0m device_config \u001b[38;5;241m=\u001b[39m DeviceConfig(\n\u001b[1;32m   1066\u001b[0m     device\u001b[38;5;241m=\u001b[39mcast(Device, current_platform\u001b[38;5;241m.\u001b[39mdevice_type))\n\u001b[0;32m-> 1067\u001b[0m model_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_model_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;66;03m# * If VLLM_USE_V1 is unset, we enable V1 for \"supported features\"\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m \u001b[38;5;66;03m#   and fall back to V0 for experimental or unsupported features.\u001b[39;00m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;66;03m# * If VLLM_USE_V1=1, we enable V1 for supported + experimental\u001b[39;00m\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;66;03m#   features and raise error for unsupported features.\u001b[39;00m\n\u001b[1;32m   1073\u001b[0m \u001b[38;5;66;03m# * If VLLM_USE_V1=0, we disable V1.\u001b[39;00m\n\u001b[1;32m   1074\u001b[0m use_v1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/vllm/engine/arg_utils.py:956\u001b[0m, in \u001b[0;36mEngineArgs.create_model_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    953\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMODEL_WEIGHTS_S3_BUCKET\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    954\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_format \u001b[38;5;241m=\u001b[39m LoadFormat\u001b[38;5;241m.\u001b[39mRUNAI_STREAMER\n\u001b[0;32m--> 956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mModelConfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhf_config_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhf_config_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallowed_local_media_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mallowed_local_media_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcode_revision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode_revision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrope_scaling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrope_scaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrope_theta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrope_theta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhf_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhf_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhf_overrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhf_overrides\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer_revision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer_revision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_model_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_model_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquantization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m    \u001b[49m\u001b[43menforce_eager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menforce_eager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_seq_len_to_capture\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_seq_len_to_capture\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_logprobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisable_sliding_window\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisable_sliding_window\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisable_cascade_attn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisable_cascade_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskip_tokenizer_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mskip_tokenizer_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_prompt_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menable_prompt_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserved_model_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserved_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlimit_mm_per_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlimit_mm_per_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmedia_io_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmedia_io_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_async_output_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisable_async_output_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    987\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmm_processor_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmm_processor_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisable_mm_preprocessor_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisable_mm_preprocessor_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    989\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverride_neuron_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moverride_neuron_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    990\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverride_pooler_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moverride_pooler_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    991\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogits_processor_pattern\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogits_processor_pattern\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    993\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverride_generation_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moverride_generation_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    994\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_sleep_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menable_sleep_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    995\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_impl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_impl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    996\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverride_attention_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moverride_attention_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    997\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/aws_neuronx_venv_pytorch_latest/lib/python3.10/site-packages/pydantic/_internal/_dataclasses.py:123\u001b[0m, in \u001b[0;36mcomplete_dataclass.<locals>.__init__\u001b[0;34m(__dataclass_self__, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    122\u001b[0m s \u001b[38;5;241m=\u001b[39m __dataclass_self__\n\u001b[0;32m--> 123\u001b[0m \u001b[43ms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mArgsKwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for ModelConfig\n  Value error, Invalid repository ID or local directory specified: '/home/ubuntu/environment/ml/qwen/compiled_model'.\nPlease verify the following requirements:\n1. Provide a valid Hugging Face repository ID.\n2. Specify a local directory that contains a recognized configuration file.\n   - For Hugging Face models: ensure the presence of a 'config.json'.\n   - For Mistral models: ensure the presence of a 'params.json'.\n3. For GGUF: pass the local path of the GGUF checkpoint.\n   Loading GGUF from a remote repo directly is not yet supported.\n [type=value_error, input_value=ArgsKwargs((), {'model': ...attention_dtype': None}), input_type=ArgsKwargs]\n    For further information visit https://errors.pydantic.dev/2.11/v/value_error"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from vllm import LLM, SamplingParams\n",
    "llm = LLM(\n",
    "    model=\"/home/ubuntu/environment/ml/qwen/compiled_model\", #local compiled model\n",
    "    max_num_seqs=1,\n",
    "    max_model_len=2048,\n",
    "    device=\"neuron\",\n",
    "    tensor_parallel_size=2,\n",
    "    override_neuron_config={})\n",
    "example1=\"\"\"\n",
    "<|im_start|>system\n",
    "You are a task management assistant. Users conversationally discuss their activities with you. From their input, output a 1-2 sentence summary.<|im_end|>\n",
    "<|im_start|>user\n",
    "Summarize what I said<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n",
    "example2=\"\"\"\n",
    "<|im_start|>system\n",
    "You are a task management assistant. Users conversationally discuss their activities with you. From their input, output a 1-2 sentence summary.<|im_end|>\n",
    "<|im_start|>user\n",
    "Summarize what I said<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n",
    "example3=\"\"\"\n",
    "<|im_start|>system\n",
    "You are a task management assistant. Users conversationally discuss their activities with you. From their input, output a 1-2 sentence summary.<|im_end|>\n",
    "<|im_start|>user\n",
    "Summarize what I said<|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n",
    "\n",
    "prompts = [\n",
    "    example1,\n",
    "    example2,\n",
    "    example3\n",
    "]\n",
    "\n",
    "sampling_params = SamplingParams(max_tokens=2048, temperature=0.8)\n",
    "outputs = llm.generate(prompts, sampling_params)\n",
    "\n",
    "print(\"#########################################################\")\n",
    "\n",
    "for output in outputs:\n",
    "    prompt = output.prompt\n",
    "    generated_text = output.outputs[0].text\n",
    "    print(f\"Prompt: {prompt!r}, \\n\\n Generated text: {generated_text!r} \\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aws_neuronx_venv_pytorch_latest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
